---
title: "Are Mass Shooting Really That Random?"
authors: Emily Tumbaco, Lorena Mancino, Rob Golebieski
output: html_notebook
---

## Problem 1 

### Importing the Dataset & Installing Necessary Packages

```{r}
shootings.dataset<-read.csv("data.csv") #importing the dataset 
shootings.dataset
```

```{r}
# install.packages('dplyr') # this package contains the mutate function which we used below 

library(dplyr)

shootings.dataset <- mutate(shootings.dataset, date= as.Date(date, format = "%m/%d/%Y"))
shootings.dataset$date # converting the dates in the data set to actual dates in R
```

### Graph 1:  Mass Shootings Before 9/11/2001 

```{r}
a <- shootings.dataset[86:118, 3]

b <- shootings.dataset[86:118, 5]

plot(a, b, main = "Mass Shootings Before 9/11/2001",xlab = "Year", ylab = "Fatalities")
```

This is a graph of all of the mass shootings that occured before 9/11/2001. The x axis contains the dates, and the y axis contains the number of fatalities from each shooting. 

### Graph 2 : Mass Shootings After 9/11/2001 

```{r}
x <- shootings.dataset[1:85, 3]

y <- shootings.dataset[1:85, 5]

plot(x, y,main = "Mass Shootings After 9/11/2001", xlab = "Year", ylab = "Fatalities")
```
This is a graph of all of the mass shootings that occured after 9/11/2001. The x axis contains the dates, and the y axis contains the number of fatalities from each shooting. 

### Graph 3 : Side By Side Comparison of Mass Shootings Before 9/11/2001 and After 9/11/2001

```{r}
par(mfrow=c(2,2))
plot(a, b, main = "Mass Shootings Before 9/11/2001",xlab = "Year", ylab = "Fatalities")
plot(x, y,main = "Mass Shootings After 9/11/2001", xlab = "Year", ylab = "Fatalities")
```

## Problem 4 

### Raster Plot - 2019 

```{r}
from.date <- as.Date('2019-01-01', format = "%Y-%m-%d")
to.date <- as.Date('2019-12-31', format = "%Y-%m-%d")

plot(NA, xlim=c(from.date, to.date), ylim=c(0,10), xlab="Day of Year", ylab="y")

segments(shootings.dataset$date, 0, y1=10)
```

### Raster Plot - 1999 

```{r}
from.date.1 <- as.Date('1999-01-01', format = "%Y-%m-%d")
to.date.1 <- as.Date('1999-12-31', format = "%Y-%m-%d")

plot(NA, xlim=c(from.date.1, to.date.1), ylim=c(0,10), xlab="Day of Year", ylab="y")

segments(shootings.dataset$date, 0, y1=10)
```

### Raster Plot - 2018

```{r}
from.date.2 <- as.Date('2018-01-01', format = "%Y-%m-%d")
to.date.2 <- as.Date('2018-12-31', format = "%Y-%m-%d")

plot(NA, xlim=c(from.date.2, to.date.2), ylim=c(0,10), xlab="Day of Year", ylab="y")

segments(shootings.dataset$date, 0, y1=10)
```

From looking at the raster plots, the mass shootings seem to occur in clusters. Every 3 months, there are approximately 3 shootings clustered together. The highest frequency of shootings occurs in the Fall months, and the lowest frequency occurs in the Summer. 

## Problem 6

### Calculating One Coefficient of Variation For The Year 2019

```{r}
tau.2019 <- as.numeric(-diff(shootings.dataset$date[2:11])) #Calculating the time between two successive mass shootings in the year 2019

tau.sd<- sd(tau.2019) 
tau.mean <- mean(tau.2019)

coef.variation <- tau.sd/tau.mean # Calculating the coefficient of variation for 2019

coef.variation-1
```

### 2019 Bootstrap Function 

```{r}
bootstrap.coef.var <- function(days, shootings){
  boot.coef <- rbinom(days, 1, shootings/days)

  if((length(which(boot.coef == 1)) == 0) || (length(which(boot.coef == 1)) == 1) || (length(which(boot.coef == 1)) == 2)){
    return(NA)
  } else {
  tau.boot <- diff(which(boot.coef == 1))-1

  tau.boot.sd <- sd(tau.boot)
  tau.boot.mean <- mean(tau.boot)
  tau.boot.variation <- (tau.boot.sd/tau.boot.mean)
  
  return(tau.boot.variation)
  }
}

bootstrap.rep <- replicate(10000, bootstrap.coef.var(365, 10))

hist(bootstrap.rep, breaks="FD")
abline(v=coef.variation)
abline(v=2-coef.variation)
```


### Centered at 0 

```{r}
hist(bootstrap.rep-1, breaks="FD")
abline(v=coef.variation-1)
abline(v=-coef.variation+1)
```

### Function for the p-value 
```{r}

bootstrap.pval<-function(days,shootings,FUN){
  
  right.tail <- bootstrap.rep-1 >= coef.variation-1 # true=values to the right of the hist 
  left.tail <- bootstrap.rep-1 <= -coef.variation+1 # true=values to the left of the hist 
  right.tail | left.tail # TRUE where they're in the right tail OR left tail
  
  pval<-(sum(right.tail | left.tail, na.rm=TRUE))/sum(!is.na(bootstrap.rep)) #p value 
  
  return(pval)
  
}

bootstrap.pval(FUN=bootstrap.coef.var(365,18))
```

If you were using a 5% significance level, you would fail to reject the null  


p-value is the prop that are as extreme or more extreme 












